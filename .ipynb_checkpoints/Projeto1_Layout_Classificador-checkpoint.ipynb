{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Carlos Andrade Inacio\n",
    "\n",
    "Nome: Carlos Felipe Borges Mesquita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\CarlosInacio\\Documents\\code\\insper\\cdados\\Projeto 1\\cdados-netflix\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'netflix.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@zanchettagui :(\\nah no show dele do netflix e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jojo vai chegar na netflix mês q vem, será q e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>com geladeira cheia, conta no banco positiva, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>estou rachando o bico com o filme cabras da pe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@twolana9 netflix \\nforças complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classificação\n",
       "0  @zanchettagui :(\\nah no show dele do netflix e...              0\n",
       "1  jojo vai chegar na netflix mês q vem, será q e...              1\n",
       "2  com geladeira cheia, conta no banco positiva, ...              0\n",
       "3  estou rachando o bico com o filme cabras da pe...              1\n",
       "4                 @twolana9 netflix \\nforças complex              0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. não\\n2. 1\\n3. peixes\\n4. não\\n5. apegada\\n6...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jpncunha1397 @arrascabigol1 @diegooliveiira_ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@netflixbrasil apanha muito também ela né netf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eu estava sem nenhuma série pra assistir e ach...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@fraannnnnnnnn final de temporada nas séries d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classificação\n",
       "0  1. não\\n2. 1\\n3. peixes\\n4. não\\n5. apegada\\n6...              0\n",
       "1  @jpncunha1397 @arrascabigol1 @diegooliveiira_ ...              0\n",
       "2  @netflixbrasil apanha muito também ela né netf...              0\n",
       "3  eu estava sem nenhuma série pra assistir e ach...              0\n",
       "4  @fraannnnnnnnn final de temporada nas séries d...              0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    " - Relevante: opinião referente ao conteúdo na plataforma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "########################         NÃO ESQUECER DE ALTERAR A QUANTIDADE DE TWEETS PROCESSADOS       ##############################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "\n",
    "\n",
    "def find_instance(start_str, end_str, string):\n",
    "    start = string.find(start_str)\n",
    "    end = string.find(end_str, start)\n",
    "    instance = ''\n",
    "    if end < start or end == None:\n",
    "        instance = string[start:]\n",
    "    else:\n",
    "        instance = string[start:end + 1]\n",
    "        \n",
    "    return instance\n",
    "\n",
    "def cleanup(serie, filtro = ''):\n",
    "    lista_tweets = []\n",
    "    punctuation = '[!-.:?;,]'\n",
    "    pattern = re.compile(punctuation)\n",
    "\n",
    "    tweets = []\n",
    "    if filtro:\n",
    "        tweets = serie[filtro]\n",
    "    else:\n",
    "        tweets = serie\n",
    "    \n",
    "    for texto in tweets:\n",
    "        # removendo emojis e pontuação\n",
    "        tweet = emoji.get_emoji_regexp().sub(u'', texto)        \n",
    "        tweet = re.sub(pattern, '', tweet)\n",
    "        \n",
    "        while '\\n' in tweet or '  ' in tweet or '\"' in tweet or \"'\" in tweet:\n",
    "            # removendo newline\n",
    "            tweet = tweet.replace('\\n', '')\n",
    "            \n",
    "            # mesmo que existam mais de 2 espaços de uma vez só, o while loop vai cortando o número de espaços\n",
    "            # até se tornar um único espaço\n",
    "            tweet = tweet.replace('  ', ' ')\n",
    "            \n",
    "            # removendo aspas\n",
    "            tweet = tweet.replace('\"', '')\n",
    "            tweet = tweet.replace(\"'\", '')\n",
    "        \n",
    "        while 'http' in tweet:\n",
    "            # removendo urls\n",
    "            url = find_instance('http', ' ', tweet)          \n",
    "            if url:\n",
    "                tweet = tweet.replace(url, '')\n",
    "        \n",
    "        while '@' in tweet:\n",
    "            # removendo menções\n",
    "            mention = find_instance('@', ' ', tweet)\n",
    "            if mention:\n",
    "                tweet = tweet.replace(mention, '')\n",
    "            \n",
    "        lista_tweets.append(tweet)\n",
    "        \n",
    "    return lista_tweets\n",
    "\n",
    "\n",
    "relevantes = train.loc[(train['Classificação'] == 1), :][\"Treinamento\"]\n",
    "irrelevantes = train.loc[(train['Classificação'] == 0), :][\"Treinamento\"]\n",
    "totais = train.loc[:, [\"Treinamento\", \"Classificação\"]]\n",
    "\n",
    "tweets_relevantes = cleanup(relevantes)\n",
    "tweets_irrelevantes = cleanup(irrelevantes)\n",
    "tweets_totais = cleanup(totais, \"Treinamento\")\n",
    "\n",
    "palavras_relevantes = []\n",
    "palavras_irrelevantes = []\n",
    "palavras_totais = []\n",
    "\n",
    "for tweet in tweets_relevantes:\n",
    "    palavras_relevantes += tweet.split()\n",
    "    palavras_totais += tweet.split()\n",
    "for tweet in tweets_irrelevantes:\n",
    "    palavras_irrelevantes += tweet.split()\n",
    "    palavras_totais += tweet.split()\n",
    "    \n",
    "serie_relevantes = pd.Series(palavras_relevantes)\n",
    "serie_irrelevantes = pd.Series(palavras_irrelevantes)\n",
    "serie_totais = pd.Series(palavras_irrelevantes)\n",
    "    \n",
    "palavras_relevantes_relativas = serie_relevantes.value_counts(True)\n",
    "palavras_irrelevantes_relativas = serie_irrelevantes.value_counts(True)\n",
    "palavras_totais_relativas = serie_totais.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilidade_tweet(_palavras, tabela_relativa, relevantes = False):\n",
    "    probabilidade = 0\n",
    "    for i in range(len(_palavras)):\n",
    "        palavra = _palavras[i]\n",
    "        if not palavra in tabela_relativa:\n",
    "            continue\n",
    "            \n",
    "        probabilidade_palavra = tabela_relativa[palavra]\n",
    "        \n",
    "        if i == 0:\n",
    "            probabilidade = probabilidade_palavra\n",
    "        else:\n",
    "            probabilidade *= probabilidade_palavra\n",
    "    \n",
    "    return probabilidade\n",
    "\n",
    "def definir_relevancia(tweet):\n",
    "    prob_relevante = len(serie_relevantes) / len(serie_totais)\n",
    "    prob_irrelevante = len(serie_irrelevantes) / len(serie_totais)\n",
    "\n",
    "    palavras = tweet.split()\n",
    "    \n",
    "    prob_tweet_dado_relevante = probabilidade_tweet(palavras, palavras_relevantes_relativas, True)\n",
    "    prob_tweet_dado_irrelevante = probabilidade_tweet(palavras, palavras_irrelevantes_relativas)\n",
    "\n",
    "    prob_relevante_tweet = prob_tweet_dado_relevante * prob_relevante\n",
    "    prob_irrelevante_tweet = prob_tweet_dado_irrelevante * prob_irrelevante\n",
    "\n",
    "    if prob_relevante_tweet > prob_irrelevante_tweet:\n",
    "        return 1\n",
    "    elif prob_relevante_tweet < prob_irrelevante_tweet:\n",
    "        return 0\n",
    "    else:\n",
    "        return '??'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% acerto: 32.77591973244147\n",
      "% erro: 67.22408026755853\n",
      "não identificados: 0\n"
     ]
    }
   ],
   "source": [
    "resultados = {\"Tweet\" : [], \"Classificação\" : []}\n",
    "\n",
    "for tweet in tweets_totais:\n",
    "    resultados[\"Tweet\"].append(tweet)\n",
    "    resultados[\"Classificação\"].append(definir_relevancia(tweet))\n",
    "    \n",
    "resultados_df = pd.DataFrame.from_dict(resultados)\n",
    "\n",
    "acertos = 0\n",
    "erros = 0\n",
    "nao_identificados = 0\n",
    "\n",
    "for indice in range(len(resultados_df)):\n",
    "    if resultados_df.iloc[[indice]][\"Classificação\"].item() == totais.iloc[[indice]][\"Classificação\"].item():\n",
    "        acertos += 1\n",
    "        continue\n",
    "    \n",
    "    if resultados_df.iloc[[indice]][\"Classificação\"].item() == \"??\":\n",
    "        nao_identificados += 1\n",
    "        continue\n",
    "    \n",
    "    erros += 1\n",
    "    \n",
    "acerto_porcentagem = (100 / (acertos + erros)) * acertos\n",
    "erro_porcentagem = (100 / (acertos + erros)) * erros\n",
    "\n",
    "print(f'% acerto: {acerto_porcentagem}\\n% erro: {erro_porcentagem}\\nnão identificados: {nao_identificados}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "totais_teste = test.loc[:,[\"Teste\", \"Classificação\"]]\n",
    "\n",
    "tweets_teste = cleanup(totais_teste, \"Teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% acerto: 48.55491329479769\n",
      "% erro: 51.445086705202314\n",
      "não identificados: 28\n"
     ]
    }
   ],
   "source": [
    "resultados = {\"Tweet\" : [], \"Classificação\" : []}\n",
    "\n",
    "for tweet in tweets_teste:\n",
    "    resultados[\"Tweet\"].append(tweet)\n",
    "    resultados[\"Classificação\"].append(definir_relevancia(tweet))\n",
    "    \n",
    "resultados_df = pd.DataFrame.from_dict(resultados)\n",
    "\n",
    "acertos = 0\n",
    "erros = 0\n",
    "nao_identificados = 0\n",
    "\n",
    "for indice in range(len(resultados_df)):\n",
    "    if resultados_df.iloc[[indice]][\"Classificação\"].item() == totais_teste.iloc[[indice]][\"Classificação\"].item():\n",
    "        acertos += 1\n",
    "        continue\n",
    "    \n",
    "    if resultados_df.iloc[[indice]][\"Classificação\"].item() == \"??\":\n",
    "        nao_identificados += 1\n",
    "        continue\n",
    "    \n",
    "    erros += 1\n",
    "    \n",
    "acerto_porcentagem = (100 / (acertos + erros)) * acertos\n",
    "erro_porcentagem = (100 / (acertos + erros)) * erros\n",
    "\n",
    "print(f'% acerto: {acerto_porcentagem}\\n% erro: {erro_porcentagem}\\nnão identificados: {nao_identificados}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
